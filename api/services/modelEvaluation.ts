import * as tf from '@tensorflow/tfjs';
import { EventEmitter } from 'events';
import { PerformanceMonitor } from './performanceMonitor.js';

export interface ModelEvaluation {
  modelName: string;
  timestamp: number;
  accuracy: number;
  precision: number;
  recall: number;
  f1Score: number;
  confidence: number;
  inferenceTime: number;
  memoryUsage: number;
  datasetSize: number;
  confusionMatrix: {
    truePositives: number;
    falsePositives: number;
    trueNegatives: number;
    falseNegatives: number;
  };
}

export interface ModelComparison {
  modelA: string;
  modelB: string;
  metric: string;
  improvement: number;
  significance: number;
  recommendation: string;
}

export class ModelEvaluationService extends EventEmitter {
  private performanceMonitor: PerformanceMonitor;
  private evaluationHistory: ModelEvaluation[] = [];
  private baselineModels: Map<string, ModelEvaluation> = new Map();
  
  constructor(performanceMonitor: PerformanceMonitor) {
    super();
    this.performanceMonitor = performanceMonitor;
  }
  
  async evaluateModel(
    modelName: string,
    model: tf.LayersModel,
    testData: tf.Tensor[],
    labels: tf.Tensor[],
    options: {
      datasetName?: string;
      confidenceThreshold?: number;
      detailedMetrics?: boolean;
    } = {}
  ): Promise<ModelEvaluation> {
    const startTime = performance.now();
    const startMemory = process.memoryUsage().heapUsed;
    
    try {
      // æ‰§è¡Œæ¨¡å‹æ¨ç†
      const predictions = model.predict(tf.stack(testData)) as tf.Tensor;
      const predictedClasses = predictions.argMax(-1);
      const actualClasses = labels.argMax(-1);
      
      // è®¡ç®—åŸºç¡€æŒ‡æ ‡
      const accuracy = this.calculateAccuracy(predictedClasses, actualClasses);
      const precision = this.calculatePrecision(predictedClasses, actualClasses);
      const recall = this.calculateRecall(predictedClasses, actualClasses);
      const f1Score = this.calculateF1Score(precision, recall);
      
      // è®¡ç®—æ··æ·†çŸ©é˜µ
      const confusionMatrix = this.calculateConfusionMatrix(predictedClasses, actualClasses);
      
      // è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
      const avgConfidence = this.calculateAverageConfidence(predictions);
      
      const endTime = performance.now();
      const endMemory = process.memoryUsage().heapUsed;
      
      const evaluation: ModelEvaluation = {
        modelName,
        timestamp: Date.now(),
        accuracy,
        precision,
        recall,
        f1Score,
        confidence: avgConfidence,
        inferenceTime: endTime - startTime,
        memoryUsage: endMemory - startMemory,
        datasetSize: testData.length,
        confusionMatrix
      };
      
      // è®°å½•åˆ°æ€§èƒ½ç›‘æ§å™¨
      this.performanceMonitor.recordModelPerformance({
        modelName,
        inferenceTime: evaluation.inferenceTime,
        accuracy: evaluation.accuracy,
        confidence: evaluation.confidence,
        memoryUsage: evaluation.memoryUsage,
        predictions: testData.length,
        timestamp: Date.now()
      });
      
      // ä¿å­˜è¯„ä¼°å†å²
      this.evaluationHistory.push(evaluation);
      
      // æ£€æµ‹å‡†ç¡®æ€§ä¸‹é™
      const recentEvaluations = this.evaluationHistory.filter(e => e.modelName === modelName).slice(-5);
      if (recentEvaluations.length >= 2) {
        const previousAccuracy = recentEvaluations[recentEvaluations.length - 2].accuracy;
        const accuracyDrop = previousAccuracy - evaluation.accuracy;
        
        if (accuracyDrop > 0.05) { // 5%ä¸‹é™é˜ˆå€¼
          this.emit('accuracy-drop', {
            modelName,
            previousAccuracy,
            currentAccuracy: evaluation.accuracy,
            accuracyDrop,
            severity: accuracyDrop > 0.1 ? 'high' : 'medium',
            timestamp: Date.now()
          });
        }
      }
      
      // æ¸…ç†å¼ é‡
      predictions.dispose();
      predictedClasses.dispose();
      
      return evaluation;
    } catch (error) {
      throw new Error(`æ¨¡å‹è¯„ä¼°å¤±è´¥: ${error.message}`);
    }
  }
  
  compareWithBaseline(modelName: string, currentEvaluation: ModelEvaluation): ModelComparison[] {
    const baseline = this.baselineModels.get(modelName);
    if (!baseline) {
      // å¦‚æœæ²¡æœ‰åŸºçº¿ï¼Œå°†å½“å‰è¯„ä¼°è®¾ä¸ºåŸºçº¿
      this.baselineModels.set(modelName, currentEvaluation);
      return [{
        modelA: 'baseline',
        modelB: modelName,
        metric: 'accuracy',
        improvement: 0,
        significance: 0,
        recommendation: 'å·²å»ºç«‹æ–°çš„åŸºçº¿æ¨¡å‹'
      }];
    }
    
    const comparisons: ModelComparison[] = [];
    
    // å‡†ç¡®æ€§æ¯”è¾ƒ
    const accuracyImprovement = currentEvaluation.accuracy - baseline.accuracy;
    comparisons.push({
      modelA: 'baseline',
      modelB: modelName,
      metric: 'accuracy',
      improvement: accuracyImprovement,
      significance: this.calculateStatisticalSignificance(accuracyImprovement, baseline.accuracy),
      recommendation: this.generateRecommendation('accuracy', accuracyImprovement)
    });
    
    // æ¨ç†æ—¶é—´æ¯”è¾ƒ
    const speedImprovement = (baseline.inferenceTime - currentEvaluation.inferenceTime) / baseline.inferenceTime;
    comparisons.push({
      modelA: 'baseline',
      modelB: modelName,
      metric: 'inferenceTime',
      improvement: speedImprovement,
      significance: Math.abs(speedImprovement),
      recommendation: this.generateRecommendation('speed', speedImprovement)
    });
    
    // å†…å­˜ä½¿ç”¨æ¯”è¾ƒ
    const memoryImprovement = (baseline.memoryUsage - currentEvaluation.memoryUsage) / baseline.memoryUsage;
    comparisons.push({
      modelA: 'baseline',
      modelB: modelName,
      metric: 'memoryUsage',
      improvement: memoryImprovement,
      significance: Math.abs(memoryImprovement),
      recommendation: this.generateRecommendation('memory', memoryImprovement)
    });
    
    return comparisons;
  }
  
  generateModelInsights(evaluations: ModelEvaluation[]): {
    strengths: string[];
    weaknesses: string[];
    optimizationOpportunities: string[];
    deploymentReadiness: number;
  } {
    const recentEvaluations = evaluations.slice(-10); // æœ€è¿‘10æ¬¡è¯„ä¼°
    
    const avgAccuracy = recentEvaluations.reduce((sum, e) => sum + e.accuracy, 0) / recentEvaluations.length;
    const avgInferenceTime = recentEvaluations.reduce((sum, e) => sum + e.inferenceTime, 0) / recentEvaluations.length;
    const avgMemoryUsage = recentEvaluations.reduce((sum, e) => sum + e.memoryUsage, 0) / recentEvaluations.length;
    
    const strengths: string[] = [];
    const weaknesses: string[] = [];
    const optimizationOpportunities: string[] = [];
    
    // å‡†ç¡®æ€§åˆ†æ
    if (avgAccuracy > 0.9) {
      strengths.push(`é«˜å‡†ç¡®æ€§ (${(avgAccuracy * 100).toFixed(1)}%)`);
    } else if (avgAccuracy < 0.7) {
      weaknesses.push(`å‡†ç¡®æ€§è¾ƒä½ (${(avgAccuracy * 100).toFixed(1)}%)`);
      optimizationOpportunities.push('è€ƒè™‘å¢åŠ è®­ç»ƒæ•°æ®æˆ–è°ƒæ•´æ¨¡å‹æ¶æ„');
    }
    
    // æ¨ç†é€Ÿåº¦åˆ†æ
    if (avgInferenceTime < 500) {
      strengths.push(`å¿«é€Ÿæ¨ç† (${avgInferenceTime.toFixed(0)}ms)`);
    } else if (avgInferenceTime > 2000) {
      weaknesses.push(`æ¨ç†é€Ÿåº¦è¾ƒæ…¢ (${avgInferenceTime.toFixed(0)}ms)`);
      optimizationOpportunities.push('è€ƒè™‘æ¨¡å‹é‡åŒ–æˆ–å‰ªæ');
    }
    
    // å†…å­˜ä½¿ç”¨åˆ†æ
    if (avgMemoryUsage < 100 * 1024 * 1024) { // 100MB
      strengths.push(`å†…å­˜ä½¿ç”¨åˆç† (${(avgMemoryUsage / 1024 / 1024).toFixed(1)}MB)`);
    } else if (avgMemoryUsage > 500 * 1024 * 1024) { // 500MB
      weaknesses.push(`å†…å­˜ä½¿ç”¨è¾ƒé«˜ (${(avgMemoryUsage / 1024 / 1024).toFixed(1)}MB)`);
      optimizationOpportunities.push('è€ƒè™‘æ¨¡å‹å‹ç¼©æˆ–åˆ†æ‰¹å¤„ç†');
    }
    
    // è®¡ç®—éƒ¨ç½²å°±ç»ªåº¦
    const deploymentReadiness = this.calculateDeploymentReadiness(avgAccuracy, avgInferenceTime, avgMemoryUsage);
    
    return {
      strengths,
      weaknesses,
      optimizationOpportunities,
      deploymentReadiness
    };
  }
  
  predictModelPerformance(modelName: string, newDataCharacteristics: {
    imageQuality: number;
    complexity: number;
    size: number;
    noiseLevel: number;
  }): {
    expectedAccuracy: number;
    expectedInferenceTime: number;
    expectedMemoryUsage: number;
    confidence: number;
    riskFactors: string[];
  } {
    const modelHistory = this.evaluationHistory.filter(e => e.modelName === modelName);
    
    if (modelHistory.length === 0) {
      return {
        expectedAccuracy: 0.8,
        expectedInferenceTime: 1000,
        expectedMemoryUsage: 200 * 1024 * 1024,
        confidence: 0.3,
        riskFactors: ['ç¼ºä¹å†å²æ•°æ®', 'é¢„æµ‹å‡†ç¡®æ€§è¾ƒä½']
      };
    }
    
    // åŸºäºå†å²æ•°æ®å’Œæ•°æ®ç‰¹å¾è¿›è¡Œé¢„æµ‹
    const recentPerformance = modelHistory.slice(-5);
    const baseAccuracy = recentPerformance.reduce((sum, e) => sum + e.accuracy, 0) / recentPerformance.length;
    const baseInferenceTime = recentPerformance.reduce((sum, e) => sum + e.inferenceTime, 0) / recentPerformance.length;
    const baseMemoryUsage = recentPerformance.reduce((sum, e) => sum + e.memoryUsage, 0) / recentPerformance.length;
    
    // æ ¹æ®æ•°æ®ç‰¹å¾è°ƒæ•´é¢„æµ‹
    let accuracyAdjustment = 0;
    let timeAdjustment = 1;
    let memoryAdjustment = 1;
    const riskFactors: string[] = [];
    
    // å›¾åƒè´¨é‡å½±å“
    if (newDataCharacteristics.imageQuality < 0.5) {
      accuracyAdjustment -= 0.2;
      riskFactors.push('å›¾åƒè´¨é‡è¾ƒå·®');
    }
    
    // å¤æ‚åº¦å½±å“
    if (newDataCharacteristics.complexity > 0.8) {
      timeAdjustment *= 1.5;
      memoryAdjustment *= 1.3;
      riskFactors.push('æ•°æ®å¤æ‚åº¦è¾ƒé«˜');
    }
    
    // å™ªå£°å½±å“
    if (newDataCharacteristics.noiseLevel > 0.6) {
      accuracyAdjustment -= 0.15;
      riskFactors.push('å™ªå£°æ°´å¹³è¾ƒé«˜');
    }
    
    return {
      expectedAccuracy: Math.max(0, Math.min(1, baseAccuracy + accuracyAdjustment)),
      expectedInferenceTime: baseInferenceTime * timeAdjustment,
      expectedMemoryUsage: baseMemoryUsage * memoryAdjustment,
      confidence: Math.max(0.1, 1 - Math.abs(accuracyAdjustment) - Math.abs(timeAdjustment - 1)),
      riskFactors
    };
  }
  
  private calculateAccuracy(predicted: tf.Tensor, actual: tf.Tensor): number {
    const predArray = predicted.arraySync() as number[];
    const actualArray = actual.arraySync() as number[];
    
    let correct = 0;
    for (let i = 0; i < predArray.length; i++) {
      if (predArray[i] === actualArray[i]) correct++;
    }
    
    return correct / predArray.length;
  }
  
  private calculatePrecision(predicted: tf.Tensor, actual: tf.Tensor): number {
    // ç®€åŒ–çš„ç²¾ç¡®åº¦è®¡ç®—
    return this.calculateAccuracy(predicted, actual); // å¯¹äºå¤šåˆ†ç±»é—®é¢˜
  }
  
  private calculateRecall(predicted: tf.Tensor, actual: tf.Tensor): number {
    // ç®€åŒ–çš„å¬å›ç‡è®¡ç®—
    return this.calculateAccuracy(predicted, actual); // å¯¹äºå¤šåˆ†ç±»é—®é¢˜
  }
  
  private calculateF1Score(precision: number, recall: number): number {
    if (precision + recall === 0) return 0;
    return 2 * (precision * recall) / (precision + recall);
  }
  
  private calculateAverageConfidence(predictions: tf.Tensor): number {
    const confidences = predictions.max(-1);
    const avgConfidence = confidences.mean().arraySync() as number;
    confidences.dispose();
    return avgConfidence;
  }
  
  private calculateConfusionMatrix(predicted: tf.Tensor, actual: tf.Tensor): any {
    const predArray = predicted.arraySync() as number[];
    const actualArray = actual.arraySync() as number[];
    
    let truePositives = 0;
    let falsePositives = 0;
    let trueNegatives = 0;
    let falseNegatives = 0;
    
    for (let i = 0; i < predArray.length; i++) {
      const pred = predArray[i];
      const act = actualArray[i];
      
      if (pred === 1 && act === 1) truePositives++;
      else if (pred === 1 && act === 0) falsePositives++;
      else if (pred === 0 && act === 0) trueNegatives++;
      else if (pred === 0 && act === 1) falseNegatives++;
    }
    
    return { truePositives, falsePositives, trueNegatives, falseNegatives };
  }
  
  private calculateStatisticalSignificance(improvement: number, baseline: number): number {
    // ç®€åŒ–çš„ç»Ÿè®¡æ˜¾è‘—æ€§è®¡ç®—
    return Math.min(1, Math.abs(improvement) / Math.max(0.01, baseline));
  }
  
  private generateRecommendation(metric: string, improvement: number): string {
    if (improvement > 0.1) {
      return `âœ… ${metric}æœ‰æ˜¾è‘—æ”¹å–„ï¼Œå»ºè®®ä¿æŒå½“å‰ç­–ç•¥`;
    } else if (improvement > 0) {
      return `ğŸ‘ ${metric}æœ‰æ‰€æ”¹å–„ï¼Œç»§ç»­è§‚å¯Ÿ`;
    } else if (improvement > -0.1) {
      return `âš ï¸ ${metric}ç•¥æœ‰ä¸‹é™ï¼Œéœ€è¦å…³æ³¨`;
    } else {
      return `ğŸš¨ ${metric}æ˜¾è‘—ä¸‹é™ï¼Œéœ€è¦ç«‹å³ä¼˜åŒ–`;
    }
  }
  
  private calculateDeploymentReadiness(accuracy: number, inferenceTime: number, memoryUsage: number): number {
    let score = 0;
    
    // å‡†ç¡®æ€§è¯„åˆ† (40%)
    if (accuracy > 0.9) score += 40;
    else if (accuracy > 0.8) score += 30;
    else if (accuracy > 0.7) score += 20;
    else score += 10;
    
    // é€Ÿåº¦è¯„åˆ† (30%)
    if (inferenceTime < 500) score += 30;
    else if (inferenceTime < 1000) score += 20;
    else if (inferenceTime < 2000) score += 10;
    else score += 5;
    
    // å†…å­˜è¯„åˆ† (30%)
    const memoryMB = memoryUsage / 1024 / 1024;
    if (memoryMB < 100) score += 30;
    else if (memoryMB < 300) score += 20;
    else if (memoryMB < 500) score += 10;
    else score += 5;
    
    return score;
  }
  
  getEvaluationHistory(modelName?: string): ModelEvaluation[] {
    if (modelName) {
      return this.evaluationHistory.filter(e => e.modelName === modelName);
    }
    return [...this.evaluationHistory];
  }
  
  // æ¨¡å‹æ¼‚ç§»æ£€æµ‹
  detectModelDrift(modelName: string, windowSize: number = 10): {
    driftDetected: boolean;
    driftMagnitude: number;
    trend: 'improving' | 'degrading' | 'stable';
    recommendation: string;
  } {
    const modelEvaluations = this.evaluationHistory
      .filter(e => e.modelName === modelName)
      .slice(-windowSize * 2); // å–ä¸¤å€çª—å£å¤§å°ç”¨äºæ¯”è¾ƒ
    
    if (modelEvaluations.length < windowSize * 2) {
      return {
        driftDetected: false,
        driftMagnitude: 0,
        trend: 'stable',
        recommendation: 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ£€æµ‹æ¨¡å‹æ¼‚ç§»'
      };
    }
    
    const recentWindow = modelEvaluations.slice(-windowSize);
    const previousWindow = modelEvaluations.slice(-windowSize * 2, -windowSize);
    
    const recentAccuracy = recentWindow.reduce((sum, e) => sum + e.accuracy, 0) / recentWindow.length;
    const previousAccuracy = previousWindow.reduce((sum, e) => sum + e.accuracy, 0) / previousWindow.length;
    
    const driftMagnitude = recentAccuracy - previousAccuracy;
    const driftDetected = Math.abs(driftMagnitude) > 0.05; // 5%é˜ˆå€¼
    
    let trend: 'improving' | 'degrading' | 'stable';
    if (driftMagnitude > 0.02) {
      trend = 'improving';
    } else if (driftMagnitude < -0.02) {
      trend = 'degrading';
    } else {
      trend = 'stable';
    }
    
    let recommendation: string;
    if (driftDetected && trend === 'degrading') {
      recommendation = 'æ£€æµ‹åˆ°æ¨¡å‹æ€§èƒ½ä¸‹é™ï¼Œå»ºè®®é‡æ–°è®­ç»ƒæˆ–æ›´æ–°æ¨¡å‹';
    } else if (driftDetected && trend === 'improving') {
      recommendation = 'æ¨¡å‹æ€§èƒ½åœ¨æ”¹å–„ï¼Œå½“å‰ç­–ç•¥æœ‰æ•ˆ';
    } else {
      recommendation = 'æ¨¡å‹æ€§èƒ½ç¨³å®šï¼Œç»§ç»­ç›‘æ§';
    }

    // å‘å‡ºæ¨¡å‹æ¼‚ç§»äº‹ä»¶
    if (driftDetected) {
      this.emit('model-drift-detected', {
        modelName,
        driftMagnitude,
        trend,
        recommendation,
        timestamp: Date.now()
      });
    }
    
    return {
      driftDetected,
      driftMagnitude,
      trend,
      recommendation
    };
  }
}